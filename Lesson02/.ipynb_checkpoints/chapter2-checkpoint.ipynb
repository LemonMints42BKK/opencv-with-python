{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d5d29f-93c4-40a8-aa98-fe5e6ec51148",
   "metadata": {},
   "source": [
    "# 2\n",
    "# Image Basic In OpenCV\n",
    "*******************\n",
    "\n",
    "In this chapter, we will cover the following topics:\n",
    ">* A theoretical introduction to image basics\n",
    ">* Concepts of pixel, colors, channels, images, and color spaces\n",
    ">* The coordinate system in OpenCV\n",
    ">* Accessing and manipulating pixels in OpenCV in different color spaces (getting and setting)\n",
    ">* BGR order in OpenCV (rather than RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34792b56-0a2a-4b92-a52f-edceaa4c28ba",
   "metadata": {},
   "source": [
    "## Technical requirements\n",
    "The technical requirements for this chapter are listed as follows:\n",
    "- [ ] Python and OpenCV\n",
    "- [ ] A Python-specific IDE\n",
    "- [ ] The NumPy and Matplotlib packages Jupyter Notebook\n",
    "- [X] Git client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eebff3f-c395-4169-aea9-dc31bfb2072d",
   "metadata": {},
   "source": [
    "## A theoretical introduction to image basics\n",
    "### Main problems in image processing\n",
    "a **two-dimensional (2D)** view of a 3D world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de7f84-318d-4300-9323-12bf721cdff2",
   "metadata": {},
   "source": [
    "* Ambiguous images because they are affected by perspective, which can produce changes in the visual appearance of the image. For example, the same object viewed from different perspectives can result in different images.\n",
    "* Images commonly affected by many factors, such as illumination, weather, reflections, and movements.\n",
    "* Objects in the image may also be occluded by other objects, making it difficult to detect or classify the occluded ones. Depending on the level of the occlusion, the required task (for example, classification of an image into some predefined categories) can be really challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1a9b9-1c18-49c7-a151-cd47ef587bd8",
   "metadata": {},
   "source": [
    "### Image-processing steps\n",
    "Image processing includes the following three steps:\n",
    "1. Get the image to work with. This process usually involves some functions so that you can read the image from different sources (camera, video stream, disk, online resources).\n",
    "2. Process the image by applying image-processing techniques to achieve the required functionality (for example, detecting a cat in an image).\n",
    "3. Show the result of the processing step (for example, drawing a bounding box in the image and then saving it to disk)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bde4d1-3ff3-4ab1-b997-b1de5e17db6b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Furthermore, step two can be broken down into three processing levels:\n",
    "* **Low-level process** usually takes an image as the input and then outputs another image. Example procedures that can be applied in this step include the following:\n",
    "    * Noise removal\n",
    "    * Image sharpening\n",
    "    * Illumination normalization\n",
    "    * Perspective correction  \n",
    "* **Mid-level process** takes the preprocessed image to output some kind of representation of the image.\n",
    "\n",
    "![the detected face](https://viso.ai/wp-content/uploads/2021/03/face-detection-viso-ai-deep-learning.jpg)\n",
    "* **High-level process** takes this vector of numbers (usually called attributes) and outputs the final result. For example, the input could be the detected face and the output could be the following:\n",
    "    * Face recognition\n",
    "\n",
    "![face recognition](https://xailient.com/wp-content/uploads/2022/08/AI-is-at-the-Edge.-What-does-this-mean-for-Face-Recognition-technology.jpg)\n",
    "    * Emotion recognition\n",
    "\n",
    "![Emotion recognition](https://labelyourdata.com/img/article-illustrations/ai_reading_faces.jpg)\n",
    "    * Drowsiness and distraction detection\n",
    "\n",
    "![Drowsiness and distraction detection](https://www.serg.ai/wp-content/uploads/2019/11/drowsiness.png)\n",
    "    * Remote heart rate measurement from the face\n",
    "\n",
    "![Remote heart rate measurement from the face](https://www.mdpi.com/applsci/applsci-09-04364/article_deploy/html/images/applsci-09-04364-g001-550.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2bd986-73b4-41e6-96e8-7ebe36c518a8",
   "metadata": {},
   "source": [
    "### Images formulation \n",
    "An image can be described as a 2D function, f(x,y), where (x,y) are the spatial coordinates and the value of f at any point, (x,y), is proportional to the brightness or gray levels of the image. Additionally, when both (x,y) and brightness values of f are all finite discrete quantities, the image is called a digital image. Therefore, f(x,y) takes the following values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a99a4e-bdcc-452e-b662-4f60b9d3d6d8",
   "metadata": {},
   "source": [
    "```\n",
    "x ∈ [0, h-1], where h is the height of the image\n",
    "y ∈ [0, w-1], where w is the width of the image\n",
    "f(x,y) ∈ [0, L-1], where L = 256 (for an 8-bit image)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5a8449-a003-4e00-a4c6-514d29128b29",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "![images](https://chortle.ccsu.edu/imagePuzzles/PartIextra/smoothingFormula.gif)\n",
    "\n",
    "We will denote these three functions subindex R, G and B for the three formulations (for the color images) as fR(x,y), fG(x,y), and fB(x,y).\n",
    "The following screenshot shows the three types of images (a color image, a grayscale image, and a black and white image):\n",
    "![the three types of images](https://www.biz-logo.com/img/grayscale.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e42263d-fb74-4605-9449-e87e555b2f16",
   "metadata": {},
   "source": [
    "## Concepts of pixels, colors, channels, images, and color spaces\n",
    "\n",
    "**The RGB model** is an additive color model in which the primary colors (R, G, B) are mixed together to reproduce a broad range of colors. As we previously stated, in the RGB model, the primary colors are red, green, and blue. Each primary color, (R, G, B), is usually called a channel, which is commonly represented as an integer value in **the [0, 255] range**. Therefore, each channel produces a total of 256 discrete values, which corresponds to the total number of bits that are used to represent the color channel value (28=256). Additionally, since there are three different channels, this is called **a 24-bit color depth**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13104734-607c-4d7c-84d0-febe1c2af223",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "![RGB](https://blog.gotprint.com/wp-content/uploads/2017/11/GP_Blog-Post_118.jpg)\n",
    "\n",
    "An image with a resolution of 800 × 1,200 is a grid with 800 columns and 1,200 rows, containing 800 × 1,200 = 960,000 pixels. It should be noted that knowing how many pixels are in an image does not indicate its physical dimensions (one pixel does not equal one millimeter). Instead, how large a pixel is (and hence, how large an image will be) will depend on the pixels per inch (PPI) that have been set for that image. A general rule of thumb is to have a PPI in the range of [200 - 400]\n",
    "> The basic equation for calculating PPI is as follows:\n",
    ">```\n",
    "> PPI = width(pixels)/width of image (inches)\n",
    "> PPI = height(pixels)/height of image (inches)\n",
    ">```\n",
    ">So, for example, if you want to print a 4 × 6 inch image, and your image is 800 × 1,200, the PPI will be 200."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d204763-43ef-4495-a9af-043df190e546",
   "metadata": {},
   "source": [
    "### File extensions\n",
    "The following file formats (with the associated file extensions) are supported by OpenCV:\n",
    "* Windows bitmaps: * *.bmp* and * *.dib*\n",
    "* JPEG files: * *.jpeg*, * *.jpg*, and * *.jpe*\n",
    "* JPEG 2000 files: * *.jp2*\n",
    "* Portable Network Graphics: * *.png*\n",
    "* Portable image format: * *.pbm*, * *.pgm*, and * *.ppm*\n",
    "* TIFF files: * *.tiff* and * *.tif*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ecf09-6c9b-41d5-a0df-dd4a6599fd7e",
   "metadata": {},
   "source": [
    "## The coordinate system in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b26a62-0c70-4f08-bfc3-8c32f30cedbd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "![coordinate](https://miro.medium.com/v2/resize:fit:720/format:webp/1*9DfMRG9YWb7gL5kmkAe9kg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c268e13-3362-44bb-8888-7b8d4f87bede",
   "metadata": {},
   "source": [
    "## Accessing and manipulating pixels in OpenCV\n",
    "### Accessing and manipulating pixels in OpenCV with BGR images\n",
    "### Accessing and manipulating pixels in OpenCV with grayscale images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6986d88a-b1e8-47c8-aa49-756c101bf478",
   "metadata": {},
   "source": [
    "## BGR order in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40263ed9-24b7-4445-b389-25ac7b50c511",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We already mentioned that OpenCV uses the BGR color format instead of the RGB one. This can be seen in the following diagram, where you can see the order of the three channels:\n",
    "![BGR](https://static.packt-cdn.com/products/9781789344912/graphics/assets/ef884cf4-46f9-4db1-b473-ed80ecbc2593.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd811257-7f92-48df-bb4c-8b7180aaba37",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The pixel structure of a BGR image can be seen in the following diagram. In particular, we have detailed how to access pixel (y=n, x=1) for clarification purposes:\n",
    "![access pixel](https://static.packt-cdn.com/products/9781789344912/graphics/assets/a4bb6560-4c40-4de2-b88f-8e08b69cf7ab.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7621b14b-05c6-4e1a-9faf-de00752644ba",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this chapter, we looked at the key concepts related to images. Images constitute rich information that's necessary to build your computer vision projects. OpenCV uses the BGR color format instead of RGB, but some Python packages (for example, Matplotlib) use the latter format. Therefore, we have covered how to convert the image from one color format into the other.\n",
    "\n",
    "Additionally, we have summarized the main functions and options to work with images:\n",
    "* To access image properties\n",
    "* Some OpenCV functions, such as cv2.imread(), cv2.split(), cv2.merge(), cv2.imshow(), cv2.waitKey(), and cv2.destroyAllWindows()\n",
    "* How to get and set image pixels in both BGR and grayscale images\n",
    "  \n",
    "Finally, we included two notebooks, which let you play with all these concepts. Remember that once you have loaded the notebook, you can run it step by step by pressing Shift + Enter or run the notebook in a single step by clicking on the Cell | Run All menu.\n",
    "In the next chapter, you will learn how to cope with files and images, which are necessary for building your computer vision applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40df93e-7469-424d-ac5a-4ff8664e37ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

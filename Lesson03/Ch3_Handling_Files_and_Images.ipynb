{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a662b165-1c49-4771-a0c2-76fe91de52e7",
   "metadata": {},
   "source": [
    "# 3\n",
    "# Handling Files and Images\n",
    "*******************\n",
    "\n",
    "In this chapter, we will cover the following topics:\n",
    "> * A theoretical introduction to handling files and images\n",
    "> * Reading/writing images\n",
    "> * Reading camera frames and video files\n",
    "> * Writing a video file\n",
    "> * Playing with video capture properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d7eac-781b-40e1-8c85-fb5d06d8f7a5",
   "metadata": {},
   "source": [
    "## An introduction to handling files and images\n",
    "This overview is summarized in the following diagram:\n",
    "![OpenCV and Python projects](https://static.packt-cdn.com/products/9781789344912/graphics/assets/5f416e00-1a15-4ad1-bbae-6c73a70d0fa0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b0762-cf6a-4f9a-9a1b-0807ade95cf6",
   "metadata": {},
   "source": [
    "### (input-processing-output) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37366fa1-5a04-4a0b-b022-60f304444ce8",
   "metadata": {},
   "source": [
    "### sys.argv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa1c580-269e-43d4-bcc3-124e6dfdfc49",
   "metadata": {},
   "source": [
    "Which can be seen in the *sysargv_python.py* example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d19f363-3e7f-4f46-983d-c31fd751d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import sys\n",
    "\n",
    "# We will print some information in connection with sys.argv to see how it works:\n",
    "print(\"The name of the script being processed is:'{}'\".format(sys.argv[0]))\n",
    "print(\"The number of arguments of the script is:'{}'\".format(len(sys.argv)))\n",
    "print(\"The arguments of the script are: '{}'\".format(sys.argv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc18121-7ce1-433c-9712-97bcc13ea61f",
   "metadata": {},
   "source": [
    "```\n",
    "# sys.argv = ['sys.argv[0] = script's name', 'sys.argv[1] = parem1' , 'sys.argv[2] = parem2',...]\n",
    "```\n",
    "Let's find out about package **sys** [click](https://docs.python.org/3/library/sys.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf1c2a0-fc3f-4081-97eb-3521ff3349cd",
   "metadata": {},
   "source": [
    "### Argparse â€“ command-line option and argument parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c33925-316a-4c01-8654-96f623aec77c",
   "metadata": {},
   "source": [
    "Pythonhas a module called argparse [**click**](https://docs.python.org/3/library/argparse.html) in\n",
    "the standard library for parsing command-line arguments. First, the program determines\n",
    "what arguments it requires. Then, argparse will work out how to parse these arguments\n",
    "to **sys.argv**. Also, argparse produces help and usage messages, and issues errors when\n",
    "invalid arguments are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2aa5fe",
   "metadata": {},
   "source": [
    "See *argparse_minimal.py* for example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd5ae32",
   "metadata": {},
   "source": [
    "See *argparse_positional_arguments.py* example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a65c97",
   "metadata": {},
   "source": [
    "See *argparse_sum_two_number.py* example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec711f3f-70ee-4712-87ce-2acc33dfc2e5",
   "metadata": {},
   "source": [
    "## Reading and writing images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059cf82-2e26-468c-b61c-36728c060052",
   "metadata": {},
   "source": [
    "In computer vision projects, images are commonly used as command-line arguments in our\n",
    "scripts. In the following sections, we are going to see how we can read and write images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4709861",
   "metadata": {},
   "source": [
    "See *argparse_load_image.py* example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bb6210-18d3-48bb-bd5c-cf74175411e3",
   "metadata": {},
   "source": [
    "### Reading images in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df0d262-4468-4d51-b754-81a5fd2656ab",
   "metadata": {},
   "source": [
    "The following example, *argparse_load_image.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f9737-ed88-4bca-bb3d-1b5c22af473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import argparse\n",
    "import cv2\n",
    "# We first create the ArgumentParser object\n",
    "# The created object 'parser' will have the necessary information\n",
    "# to parse the command-line arguments into data types.\n",
    "parser = argparse.ArgumentParser()\n",
    "# We add 'path_image' argument using add_argument() including a help. The type of this argument is string (by default)\n",
    "parser.add_argument(\"path_image\", help=\"path to input image to be displayed\")\n",
    "# The information about program arguments is stored in 'parser'\n",
    "# Then, it is used when the parser calls parse_args().\n",
    "# ArgumentParser parses arguments through the parse_args() method:\n",
    "args = parser.parse_args()\n",
    "# We can now load the input image from disk:\n",
    "image = cv2.imread(args.path_image)\n",
    "# Parse the argument and store it in a dictionary:\n",
    "args = vars(parser.parse_args())\n",
    "# Now, we can also load the input image from disk using args:\n",
    "image2 = cv2.imread(args[\"path_image\"])\n",
    "# Show the loaded image:\n",
    "cv2.imshow(\"loaded image\", image)\n",
    "cv2.imshow(\"loaded image2\", image2)\n",
    "# Wait until a key is pressed:\n",
    "cv2.waitKey(0)\n",
    "# Destroy all windows:\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472f142-6d1e-4380-be95-bef1de369db4",
   "metadata": {},
   "source": [
    "* In this example, the required argument is **path_image**, which contains the path of the\n",
    "image we want to load.\n",
    "* The path of the image is a **string**.\n",
    "* Both **args.path_image** and **args\\[\"path_image\"\\]** will contain the path of the image (two\n",
    "different ways of getting the value from the parameter), so we will use them as the\n",
    "parameter of the **cv2.imread()** function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcc9a2-0338-4fe5-96c3-4ffa4b8214a2",
   "metadata": {},
   "source": [
    "### Reading and writing images in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb8be3c-76c2-43e1-a0b3-aedf492277ca",
   "metadata": {},
   "source": [
    "In the following example, these three steps (load, processing, and save) are introduced. In this\n",
    "case, the processing step is very simple (convert the image into grayscale). This can be seen\n",
    "in the following "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc73fbc",
   "metadata": {},
   "source": [
    "example, *argparse_load_processing_save_image.py*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6927fb-88ea-4804-9198-6bcdf1510a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import argparse\n",
    "import cv2\n",
    "# We first create the ArgumentParser object\n",
    "# The created object 'parser' will have the necessary information\n",
    "# to parse the command-line arguments into data types.\n",
    "parser = argparse.ArgumentParser()\n",
    "# Add 'path_image_input' argument using add_argument() including a help.\n",
    "# The type is string (by default):\n",
    "parser.add_argument(\"path_image_input\", help=\"path to input image to be displayed\")\n",
    "# Add 'path_image_output' argument using add_argument() including a help.\n",
    "# The type is string (by default):\n",
    "parser.add_argument(\"path_image_output\", help=\"path of the processed image to be saved\")\n",
    "# Parse the argument and store it in a dictionary:\n",
    "args = vars(parser.parse_args())\n",
    "# We can load the input image from disk:\n",
    "image_input = cv2.imread(args[\"path_image_input\"])\n",
    "# Show the loaded image:\n",
    "cv2.imshow(\"loaded image\", image_input)\n",
    "# Process the input image (convert it to grayscale):\n",
    "gray_image = cv2.cvtColor(image_input, cv2.COLOR_BGR2GRAY)\n",
    "# Show the processed image:\n",
    "cv2.imshow(\"gray image\", gray_image)\n",
    "# Save the processed image to disk:\n",
    "cv2.imwrite(args[\"path_image_output\"], gray_image)\n",
    "# Wait until a key is pressed:\n",
    "cv2.waitKey(0)\n",
    "# Destroy all windows:\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb77cfb-f2cb-42d1-92d9-474178278be8",
   "metadata": {},
   "source": [
    "* In this previous example, there are **two required arguments**.\n",
    "* The first one is **path_image_input**, which contains the path of the image we want to load. The path of\n",
    "the image is a string. Therefore, no type should be included in the positional argument\n",
    "because it is a string by default.\n",
    "* The second one is **path_image_output**, which contains the path of the resulting image we want to save. In this example, the processing step consists of converting the loaded image into grayscale:\n",
    "```  \n",
    "# Process the input image (convert it to grayscale)\n",
    "gray_image = cv2.cvtColor(image_input, cv2.COLOR_BGR2GRAY)\n",
    "```\n",
    "* It should be noted that the second argument, **cv2.COLOR_BGR2GRAY**, assumes that the\n",
    "loaded image is a *BGR color image*. If you have loaded an *RGB color* image and you want\n",
    "to convert it into grayscale, you should use **cv2.COLOR_RGB2GRAY**.\n",
    "* This is a very simple processing step, but it is included for the sake of simplicity. In future\n",
    "chapters, more elaborate processing algorithms will be shown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a171e63-8e85-47a3-8325-800a4b3fb1cd",
   "metadata": {},
   "source": [
    "## Reading camera frames and video \n",
    "In some projects, you have to capture camera frames (for example, capture frames with the\n",
    "webcam of your laptop). In OpenCV, we have **cv2.VideoCapture**, which is a class for\n",
    "video capturing from different sources, such as image sequences, video files, and cameras.\n",
    "In this section, we are going to see some examples to introduce us to this class for capturing\n",
    "camera frames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3664bd1-8224-46e1-bdcd-e79d2b73a9b6",
   "metadata": {},
   "source": [
    "### Reading camera frames\n",
    "This first example, *read_camera.py*, shows you how to read frames from a camera that's\n",
    "connected to your computer.\n",
    "> a webcam to your computer, it has an index of **0**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f392cf",
   "metadata": {},
   "source": [
    "example, *read_camera.py*:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7b59d-92e8-4a06-b759-8ff9328bb593",
   "metadata": {},
   "source": [
    "### Accessing some properties of the capture object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733e9563",
   "metadata": {},
   "source": [
    "Finally, you can access some properties of the capture object\n",
    "using capture.get(property_identifier). In this case, we get some properties, such\n",
    "as frame width, frame height, and frames per second (fps). If we call a property that is not\n",
    "supported, the returned value will be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c2a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the required packages\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "# We first create the ArgumentParser object\n",
    "# The created object 'parser' will have the necessary information\n",
    "# to parse the command-line arguments into data types.\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# We add 'index_camera' argument using add_argument() including a help.\n",
    "parser.add_argument(\"index_camera\", help=\"index of the camera to read from\", type=int)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# We create a VideoCapture object to read from the camera (pass 0):\n",
    "capture = cv2.VideoCapture(args.index_camera)\n",
    "\n",
    "# Get some properties of VideoCapture (frame width, frame height and frames per second (fps)):\n",
    "frame_width = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frame_height = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Print these values:\n",
    "print(\"CV_CAP_PROP_FRAME_WIDTH: '{}'\".format(frame_width))\n",
    "print(\"CV_CAP_PROP_FRAME_HEIGHT : '{}'\".format(frame_height))\n",
    "print(\"CAP_PROP_FPS : '{}'\".format(fps))\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if capture.isOpened()is False:\n",
    " print(\"Error opening the camera\")\n",
    "\n",
    "# Read until video is completed\n",
    "while capture.isOpened():\n",
    " # Capture frame-by-frame from the camera\n",
    " ret, frame = capture.read()\n",
    "\n",
    "if ret is True:\n",
    "\t# Display the captured frame:\n",
    "\tcv2.imshow('Input frame from the camera', frame)\n",
    "\n",
    "\t# Convert the frame captured from the camera to grayscale:\n",
    "\tgray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t# Display the grayscale frame:\n",
    "\tcv2.imshow('Grayscale input camera', gray_frame)\n",
    "\n",
    "\t# Press q on keyboard to exit the program\n",
    "\tif cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "\t\tbreak\n",
    "\n",
    " # Break the loop\n",
    "else:\n",
    "\tbreak\n",
    "# Release everything:\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0b2a3-8481-4ac7-b99d-4ac766d4d649",
   "metadata": {},
   "source": [
    "### Saving camera frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652128db",
   "metadata": {},
   "source": [
    "example, *read_camera_capture.py* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e7705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press c on keyboard to save current frame\n",
    "if cv2.waitKey(20) & 0xFF == ord('c'):\n",
    "\tframe_name = \"camera_frame_{}.png\".format(frame_index)\n",
    "\tgray_frame_name = \"grayscale_camera_frame_{}.png\".format(frame_index)\n",
    "\tcv2.imwrite(frame_name, frame)\n",
    "\tcv2.imwrite(gray_frame_name, gray_frame)\n",
    "\tframe_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7b5b5",
   "metadata": {},
   "source": [
    "> ord('c') returns the value representing the c character using eight bits. Additionally,\n",
    "the cv2.waitKey() value is bitwise AND using the & operator with 0xFF to get only its\n",
    "last eight bits. Therefore, we can perform a comparison between these two 8-bit values.\n",
    "When the C key is pressed, we build the names for both frames. Then, we save the two\n",
    "images to disk. Finally, frame_index is incremented so that it's ready for the next frame to\n",
    "be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c328ddcd",
   "metadata": {},
   "source": [
    "Check out *read_camera_capture.py* to see the full code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dccfd3-4a32-426d-b985-f90d9144967d",
   "metadata": {},
   "source": [
    "### Reading a video file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b801beed",
   "metadata": {},
   "source": [
    "cv2.VideoCapture also allows us to read a video file. Therefore, to read a video file, the \n",
    "path to the video file should be provided when creating the cv2.VideoCapture object:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6773c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first create the ArgumentParser object\n",
    "# The created object 'parser' will have the necessary information\n",
    "# to parse the command-line arguments into data types.\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# We add 'video_path' argument using add_argument() including a help.\n",
    "parser.add_argument(\"video_path\", help=\"path to the video file\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Create a VideoCapture object. In this case, the argument is the video file name:\n",
    "capture = cv2.VideoCapture(args.video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e8ba3",
   "metadata": {},
   "source": [
    "Check out *read_video_file.py* to see the full example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0bec9d-53c5-4f5f-a487-96ac7d41b0f1",
   "metadata": {},
   "source": [
    "### Reading from an IP camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03728cc1",
   "metadata": {},
   "source": [
    "To finish with cv2.VideoCapture, we are going to see how we can read from an IP\n",
    "camera. Reading from an IP camera in OpenCV is very similar to reading from a file. In this\n",
    "sense, only the parameter to the constructor of cv2.VideoCapture should be changed.\n",
    "The good thing about this is that you do not need an IP camera in your local network to try\n",
    "this functionality. There are many public IP cameras you can try to connect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba091e",
   "metadata": {},
   "source": [
    " For example,\n",
    "we are going to connect to an IP public camera, which is placed at *Club NÃ utic Port de la\n",
    "Selva â€“ Costa Brava â€“ Cap de Creus (Girona, Spain)*.\n",
    "\n",
    "The web page of this port is hosted\n",
    "at https://www.cnps.cat/. You can navigate to the webcam sections [webcam](https://www.cnps.cat/webcams/) to find some webcams to connect with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f97331",
   "metadata": {},
   "source": [
    "If you execute this example *read_ip_camera.py*,\n",
    "\n",
    "you should see something similar to the following\n",
    "screenshot, where both the BGR and the grayscale images that were obtained from the IP\n",
    "camera are shown:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f996a2d-5bf2-4a08-a094-29dd53daed41",
   "metadata": {},
   "source": [
    "## Writing a video file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0049cacf",
   "metadata": {},
   "source": [
    "> In this section, we are going to see how we can write to video files using\n",
    "cv2.VideoWriter. However some concepts (for example, fps, codecs, and video file\n",
    "formats) should be introduced first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bda268-d058-4d6e-9f28-374116b620e8",
   "metadata": {},
   "source": [
    "* ### Calculating frames per second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcf1ec5",
   "metadata": {},
   "source": [
    "> fps is an important metric in computer vision projects.\n",
    "This metric indicates how many frames are processed per second."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcb1add",
   "metadata": {},
   "source": [
    "For example,\n",
    "if your algorithm should track and detect people walking down the street, 15 fps is\n",
    "probably enough. But if your goal is to detect and track cars going fast on a highway, 20-25\n",
    "fps are probably necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68bba6a",
   "metadata": {},
   "source": [
    "In the following example, *read_camera_fps.py*, we are going to\n",
    "modify *read_camera.py* to output the number of fps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a327e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read until the video is completed, or 'q' is pressed\n",
    "while capture.isOpened():\n",
    "\t# Capture frame-by-frame from the camera\n",
    "\tret, frame = capture.read()\n",
    "\n",
    "if ret is True:\n",
    "\t# Calculate time before processing the frame:\n",
    "\tprocessing_start = time.time()\n",
    "\t# All the processing should be included here\n",
    "\t# ...\n",
    "\t# ...\n",
    "\t# End of processing\n",
    "\t# Calculate time after processing the frame\n",
    "\tprocessing_end = time.time()\n",
    "\t# Calculate the difference\n",
    "\tprocessing_time_frame = processing_end - processing_start\n",
    "\t# FPS = 1 / time_per_frame\n",
    "\t# Show the number of frames per second\n",
    "\tprint(\"fps: {}\".format(1.0 / processing_time_frame))\n",
    "\n",
    "# Break the loop\n",
    "else:\n",
    "\tbreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d307d6b",
   "metadata": {},
   "source": [
    "First, we take the time before the processing is done:\n",
    "\n",
    "```processing_start = time.time()```\n",
    "\n",
    "Then, we take the time after all the processing is done:\n",
    "\n",
    "```processing_end = time.time()```\n",
    "\n",
    "Following that, we calculate the difference:\n",
    "\n",
    "``processing_time_frame = processing_end - processing_start``\n",
    "\n",
    "Finally, we calculate and print the number of fps:\n",
    "\n",
    "```print(\"fps: {}\".format(1.0 / processing_time_frame))```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e03beb-c325-47a0-97b8-701d9c8ea082",
   "metadata": {},
   "source": [
    "* ### Considerations for writing a video file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3340d335",
   "metadata": {},
   "source": [
    "> A video code is a piece of software that's used to both compress and decompress a digital\n",
    "video. Therefore, a codec can be used to convert an uncompressed video into a compressed\n",
    "one, or it can be used to convert a compressed video to an uncompressed one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dae455",
   "metadata": {},
   "source": [
    "![This diagram summarizes the main considerations you should take into account when\n",
    "creating a video file using cv2.VideoWriter() in OpenCV](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FA5IqG%2Fbtq2gwSdzd4%2FxuoddiRwQMPLLUj6H547L1%2Fimg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76080be6",
   "metadata": {},
   "source": [
    "**videocompression specification or video coding format**\n",
    "\n",
    "#### FOURCC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4add6d6",
   "metadata": {},
   "source": [
    "FOURCC stands for four character code. The list of all available codes can be seen at http://www.fourcc.org/codecs.php. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ee780",
   "metadata": {},
   "source": [
    " This means that if you want to work with a specific codec,\n",
    "this codec should already be installed on your system. Typical codecs\n",
    "are DIVX, XVID, X264, and MJPG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f70d55",
   "metadata": {},
   "source": [
    "> Additionally, a video file format is a type of file format that's used to store digital video\n",
    "data. Typical video file formats are AVI (*.avi), MP4 (*.mp4), QuickTime (*.mov), and\n",
    "Windows Media Video (*.wmv). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e22d09",
   "metadata": {},
   "source": [
    "the following example, *write_video_file.py*, writes a video file and it can\n",
    "also be helpful to play with these concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a20ba06-8e72-422f-9629-921efa6f912a",
   "metadata": {},
   "source": [
    "## Playing with video capture properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f65df66",
   "metadata": {},
   "source": [
    "> In some of the previous examples, we saw how to get some properties from the\n",
    "cv2.VideoCapture object. In this section, we are going to see how we can get all of the\n",
    "properties and understand how they work. Finally, we are going to use these properties to\n",
    "load a video file and output it backwards (showing the last frame of the video first and so\n",
    "on)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7466d75-256a-4664-9f07-750f114835bb",
   "metadata": {},
   "source": [
    "* ### Getting all the properties from the video capture object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f3f39",
   "metadata": {},
   "source": [
    "First, we create the *read_video_file_all_properties.py* script to show all the\n",
    "properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beaaa49",
   "metadata": {},
   "source": [
    ">  In these cases, a 0 value is returned. Additionally, we have created\n",
    "the decode_fourcc() function, which converts the value that's returned\n",
    "by capture.get(cv2.CAP_PROP_FOURCC) as a string value that contains the int\n",
    "representation of the codec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03816d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_fourcc(fourcc):\n",
    " \"\"\"\n",
    " Decodes the fourcc value to get the four chars identifying it\n",
    "\n",
    " \"\"\"\n",
    " fourcc_int = int(fourcc)\n",
    "\n",
    " # We print the int value of fourcc\n",
    " print(\"int value of fourcc: '{}'\".format(fourcc_int))\n",
    "\n",
    "# We can also perform this in one line:\n",
    "# return \"\".join([chr((fourcc_int >> 8 * i) & 0xFF) for i in range(4)])\n",
    "\n",
    "fourcc_decode = \"\"\n",
    "for i in range(4):\n",
    " \tint_value = fourcc_int >> 8 * i & 0xFF\n",
    "    print(\"int_value: '{}'\".format(int_value))\n",
    "\tfourcc_decode += chr(int_value)\n",
    "return fourcc_decode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f17d322",
   "metadata": {},
   "source": [
    "![the following diagram summarizes the main steps:](https://img-blog.csdnimg.cn/8d4049fa6d314d76b41950f5d3f08372.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xPVkVteTEzNDYxMQ==,size_16,color_FFFFFF,t_70#pic_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfae6bd",
   "metadata": {},
   "source": [
    "You can view the full code of this script in\n",
    "the *read_video_file_all_properties.py* file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ab0c0-92d7-45b0-8341-e05425c69bfd",
   "metadata": {},
   "source": [
    "* ### Using the properties â€“ playing a video backwards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df77dc65",
   "metadata": {},
   "source": [
    "To see how we can use the aforementioned properties, we are going to understand the\n",
    "read_video_file_backwards.py script, which uses some of these properties to load a\n",
    "video and output it backwards, showing the last frame of the video first and so on. We are\n",
    "going to use the following properties:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b54eb1",
   "metadata": {},
   "source": [
    "* cv2.CAP_PROP_FRAME_COUNT: This property provides the total number of\n",
    "frames\n",
    "* cv2.CAP_PROP_POS_FRAMES: This property provides the current frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4361bf47",
   "metadata": {},
   "source": [
    "The first step is to get the index of the last frame:\n",
    "\n",
    "```\n",
    "# We get the index of the last frame of the video file\n",
    "frame_index = capture.get(cv2.CAP_PROP_FRAME_COUNT) - 1\n",
    "```\n",
    "\n",
    "Therefore, we set the current frame to read to this position:\n",
    "\n",
    "```\n",
    "# We set the current frame position\n",
    " capture.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "```\n",
    "\n",
    "This way, we can read this frame as usual:\n",
    "\n",
    "```\n",
    "# Capture frame-by-frame from the video file\n",
    " ret, frame = capture.read()\n",
    "```\n",
    "\n",
    "Finally, we decrement the index in order to read the next frame from the video file:\n",
    "\n",
    "```\n",
    "# Decrement the index to read next frame\n",
    " frame_index = frame_index - 1\n",
    "```\n",
    "\n",
    "The full code is provided in the read_video_file_backwards.py script. This script can\n",
    "be easily modified to save the resulting video playing backwards (not only showing it).\n",
    "This script is proposed in the Question section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59abcf7-4156-462d-8a0f-093e2607f54b",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67f6ead",
   "metadata": {},
   "source": [
    "In this chapter, we saw that working with images and files is a key element of computer\n",
    "vision projects. A common approach in this kind of project is to load some images first,\n",
    "perform some processing, and then output the processed images. In this chapter, we\n",
    "reviewed this flow. Additionally, in connection with video streams, both\n",
    "cv2.VideoCapture and cv2.VideoWriter were covered. We also looked at the\n",
    "cv2.VideoWriter class for video writing. Two key aspects were reviewed when writing\n",
    "video filesâ€”video codecs (for example, DIVX) and video file formats (for example, AVI). To\n",
    "work with video codecs, OpenCV provides FOURCC, a four-byte code. Typical codecs are\n",
    "DIVX, XVID, X264, and MJPG, while typical video file formats are AVI (*.avi), MP4\n",
    "(*.mp4), QuickTime (*.mov), and Windows Media Video (*.wmv).\n",
    "\n",
    "\n",
    "We also reviewed the concept of fps and how to calculate it in our programs. Additionally,\n",
    "we looked at how to get all the properties of the cv2.VideoCapture object and how to use\n",
    "them to load a video and output it backwards, showing the last frame of the video\n",
    "first. Finally, we saw how to cope with command-line arguments. Python uses sys.argv to\n",
    "handle command-line arguments. When our programs take complex parameters or\n",
    "multiple filenames, we should use Python's argparse library.\n",
    "\n",
    "In the next chapter, we are going to learn how to draw basic and more advanced shapes\n",
    "using the OpenCV library. OpenCV provides functions to draw lines, circles, rectangles,\n",
    "ellipses, text, and polylines. In connection with computer vision projects, it is a common\n",
    "approach to draw basic shapes in the image in order to do the following:\n",
    "* Show some intermediate results of your algorithm (for example, bounding box of\n",
    "the detected objects)\n",
    "* Show the final results of your algorithm (for example, the class of the detected\n",
    "objects, such as cars, cats, or dogs)\n",
    "* Show some debugging information (for example, execution time)\n",
    "\n",
    "Therefore, the next chapter can be of great help in connection with your computer vision\n",
    "algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
